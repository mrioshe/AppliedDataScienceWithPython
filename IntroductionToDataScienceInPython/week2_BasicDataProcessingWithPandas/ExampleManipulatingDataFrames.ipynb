{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DataFrame` Example\n",
    "\n",
    "In this lecture I'm going to walk through a basic data cleaning process with you and introduce you to a few more pandas API functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by bringing in pandas\n",
    "import pandas as pd\n",
    "# And load our dataset. We're going to be cleaning the list of presidents in the US from wikipedia\n",
    "df=pd.read_csv(\"datasets/presidents.csv\")\n",
    "# And lets just take a look at some of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, we have some presidents, some dates, I see a bunch of footnotes in the \"Born\" column which might cause\n",
    "# issues. Let's start with cleaning up that name into firstname and lastname. I'm going to tackle this with\n",
    "# a regex. So I want to create two new columns and apply a regex to the projection of the \"President\" column.\n",
    "\n",
    "# Here's one solution, we could make a copy of the President column\n",
    "df[\"First\"]=df['President']\n",
    "# Then we can call replace() and just have a pattern that matches the last name and set it to an empty string\n",
    "df[\"First\"]=df[\"First\"].replace(\"[ ].*\", \"\", regex=True)\n",
    "# Now let's take a look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That works, but it's kind of gross. And it's slow, since we had to make a full copy of a column then go\n",
    "# through and update strings. There are a few other ways we can deal with this. Let me show you the most \n",
    "# general one first, and that's called the apply() function. Let's drop the column we made first\n",
    "del(df[\"First\"])\n",
    "\n",
    "# The apply() function on a dataframe will take some arbitrary function you have written and apply it to\n",
    "# either a Series (a single column) or DataFrame across all rows or columns. Lets write a function which\n",
    "# just splits a string into two pieces using a single row of data\n",
    "def splitname(row):\n",
    "    # The row is a single Series object which is a single row indexed by column values\n",
    "    # Let's extract the firstname and create a new entry in the series\n",
    "    row['First']=row['President'].split(\" \")[0]\n",
    "    # Let's do the same with the last word in the string\n",
    "    row['Last']=row['President'].split(\" \")[-1]\n",
    "    # Now we just return the row and the pandas .apply() will take of merging them back into a DataFrame\n",
    "    return row\n",
    "\n",
    "# Now if we apply this to the dataframe indicating we want to apply it across columns\n",
    "df=df.apply(splitname, axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty questionable as to whether that is less gross, but it achieves the result and I find that I use the\n",
    "# apply() function regularly in my work. The pandas series has a couple of other nice convenience functions\n",
    "# though, and the next I would like to touch on is called .extract(). Lets drop our firstname and lastname.\n",
    "del(df['First'])\n",
    "del(df['Last'])\n",
    "\n",
    "# Extract takes a regular expression as input and specifically requires you to set capture groups that\n",
    "# correspond to the output columns you are interested in. And, this is a great place for you to pause the\n",
    "# video and reflect - if you were going to write a regular expression that returned groups and just had the\n",
    "# firstname and lastname in it, what would that look like?\n",
    "\n",
    "# Here's my solution, where we match three groups but only return two, the first and the last name\n",
    "pattern=\"(^[\\w]*)(?:.* )([\\w]*$)\"\n",
    "\n",
    "# Now the extract function is built into the str attribute of the Series object, so we can call it\n",
    "# using Series.str.extract(pattern)\n",
    "df[\"President\"].str.extract(pattern).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So that looks pretty nice, other than the column names. But if we name the groups we get named columns out\n",
    "pattern=\"(?P<First>^[\\w]*)(?:.* )(?P<Last>[\\w]*$)\"\n",
    "\n",
    "# Now call extract\n",
    "names=df[\"President\"].str.extract(pattern).head()\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can just copy these into our main dataframe if we want to\n",
    "df[\"First\"]=names[\"First\"]\n",
    "df[\"Last\"]=names[\"Last\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's worth looking at the pandas str module for other functions which have been written specifically\n",
    "# to clean up strings in DataFrames, and you can find that in the docs in the Working with Text\n",
    "# section: https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets move on to clean up that Born column. First, let's get rid of anything that isn't in the\n",
    "# pattern of Month Day and Year.\n",
    "df[\"Born\"]=df[\"Born\"].str.extract(\"([\\w]{3} [\\w]{1,2}, [\\w]{4})\")\n",
    "df[\"Born\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, that cleans up the date format. But I'm going to foreshadow something else here - the type of this\n",
    "# column is object, and we know that's what pandas uses when it is dealing with string. But pandas actually\n",
    "# has really interesting date/time features - in fact, that's one of the reasons Wes McKinney put his efforts\n",
    "# into the library, to deal with financial transactions. So if I were building this out, I would actually\n",
    "# update this column to the write data type as well\n",
    "df[\"Born\"]=pd.to_datetime(df[\"Born\"])\n",
    "df[\"Born\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would make subsequent processing on the dataframe around dates, such as getting every President who\n",
    "# was born in a given time span, much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, most of the other columns in this dataset I would clean in a similar fashion. And this would be a good practice activity for you, so I would recommend that you pause the video, open up the notebook for the lecture if you don't already have it opened, and then finish cleaning up this dataframe. In this lecture I introduced you to the str module which has a number of important functions for cleaning pandas dataframes. You don't have to use these - I actually use apply() quite a bit myself, especially if I don't need high performance data cleaning because my dataset is small. But the str functions are incredibly useful and build on your existing knowledge of regular expressions, and because they are vectorized they are efficient to use as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
